{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/louismartin/ammi-2021-bordes-deep-nlp/blob/master/lab2/ammi_dnlp_lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzBHf68UXD2k"
   },
   "source": [
    "# Chit Chat Chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jm6rTDCrXJ4V"
   },
   "source": [
    "In the previous lab, we explored models that try to answer questions by reasoning over free-text input. In this lab, we will explore two types of models to create chatbots.\n",
    "\n",
    "First, let's consider important qualities for a chit-chat chatbot system\n",
    "\n",
    "\n",
    "1.   **Readability** - whatever model we use, the chats it creates should be easily understood by humans\n",
    "2.   **Consistency** - when chatting with a chatbot, the bot should maintain consistent information. Imagine a bot that says \"Hi I'm Jack'' and then \"Hello, my name is Jane\" - quite confusing\n",
    "3.    **Engaging** - To encourage users to talk to the bot, the bot should be able to generate interesting, engaging responses. If the only response was \"wow, that's cool,\" users are quite unlikely to want to talk very much to the chat bot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "LrYcmfoI5PWO",
    "outputId": "28f3e4b8-224b-4fb5-9974-726b5c584743"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='color: blue;'>\n",
       "  Throughout the lab, there will be <b>questions</b> you should answer. <b>All questions you need to write an answer to will be in this blue color.</b>\n",
       "  \n",
       "  <br>Please write brief answers- no need for long explanations. \n",
       "  <br>There can be multiple correct answers to the questions.\n",
       "  \n",
       "  <br><br>The goal of these questions is to:\n",
       "  <ul style='color: green;'>\n",
       "    <li> Review the lecture material in the context of practical models and develop intuition about the models\n",
       "    <li> Develop a sense of experimentation - we will pretend we have a dataset and will walk through an experimental thought process.\n",
       "  </ul>\n",
       "\n",
       "<b>We are going to do the lab as a group. <br>I will explain the sections in more depth, as we did not cover dialogue deeply during the lecture. <br> After we discuss, I will provide time for you to write a few sentences. At the end of the lab, you will hand it in. In theory, everyone should be finished together!</b>\n",
       "\n",
       "  \n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<p style='color: blue;'>\n",
    "  Throughout the lab, there will be <b>questions</b> you should answer. <b>All questions you need to write an answer to will be in this blue color.</b>\n",
    "  \n",
    "  <br>Please write brief answers- no need for long explanations. \n",
    "  <br>There can be multiple correct answers to the questions.\n",
    "  \n",
    "  <br><br>The goal of these questions is to:\n",
    "  <ul style='color: green;'>\n",
    "    <li> Review the lecture material in the context of practical models and develop intuition about the models\n",
    "    <li> Develop a sense of experimentation - we will pretend we have a dataset and will walk through an experimental thought process.\n",
    "  </ul>\n",
    "\n",
    "<b>We are going to do the lab as a group. <br>I will explain the sections in more depth, as we did not cover dialogue deeply during the lecture. <br> After we discuss, I will provide time for you to write a few sentences. At the end of the lab, you will hand it in. In theory, everyone should be finished together!</b>\n",
    "\n",
    "  \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3zg0WczXjDs"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kguDIJbLXmZU"
   },
   "source": [
    "The dataset we will use for this lab is called `PersonaChat` - it was created to directly address problem 2. Each person talking in the dataset has a personality, which helps maintain consistency in the dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpvTb8bBX40A",
    "outputId": "38d8d258-85ce-4e60-aa92-95dc6950f801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into './ParlAI'...\n",
      "remote: Enumerating objects: 39174, done.\u001b[K\n",
      "remote: Counting objects: 100% (428/428), done.\u001b[K\n",
      "remote: Compressing objects: 100% (318/318), done.\u001b[K\n",
      "remote: Total 39174 (delta 174), reused 310 (delta 104), pack-reused 38746\u001b[K\n",
      "Receiving objects: 100% (39174/39174), 64.98 MiB | 32.32 MiB/s, done.\n",
      "Resolving deltas: 100% (27906/27906), done.\n",
      "Note: checking out 'convai2archive'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by performing another checkout.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -b with the checkout command again. Example:\n",
      "\n",
      "  git checkout -b <new-branch-name>\n",
      "\n",
      "HEAD is now at 8c79dac4 add documentation for MEssages (#2339)\n",
      "running develop\n",
      "running egg_info\n",
      "creating parlai.egg-info\n",
      "writing parlai.egg-info/PKG-INFO\n",
      "writing dependency_links to parlai.egg-info/dependency_links.txt\n",
      "writing entry points to parlai.egg-info/entry_points.txt\n",
      "writing requirements to parlai.egg-info/requires.txt\n",
      "writing top-level names to parlai.egg-info/top_level.txt\n",
      "writing manifest file 'parlai.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n",
      "reading manifest template 'MANIFEST.in'\n",
      "writing manifest file 'parlai.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "Creating /usr/local/lib/python3.7/dist-packages/parlai.egg-link (link to .)\n",
      "Adding parlai 0.1.0 to easy-install.pth file\n",
      "\n",
      "Installed /content/ParlAI\n",
      "Processing dependencies for parlai==0.1.0\n",
      "Searching for websocket-server==0.4\n",
      "Reading https://pypi.org/simple/websocket-server/\n",
      "Downloading https://files.pythonhosted.org/packages/74/64/e86581ee7775a2e08aca530b41e1a1e3ee6b320233b1eff301dcb86d1636/websocket_server-0.4.tar.gz#sha256=91cd4b565d1e1b00ef107abcb2840a8090868b19543f3b38e1962d5f975d0c04\n",
      "Best match: websocket-server 0.4\n",
      "Processing websocket_server-0.4.tar.gz\n",
      "Writing /tmp/easy_install-1jhj80sz/websocket_server-0.4/setup.cfg\n",
      "Running websocket_server-0.4/setup.py -q bdist_egg --dist-dir /tmp/easy_install-1jhj80sz/websocket_server-0.4/egg-dist-tmp-zcebs_d4\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "Moving websocket_server-0.4-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
      "Adding websocket-server 0.4 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/websocket_server-0.4-py3.7.egg\n",
      "Searching for websocket-client==0.56.0\n",
      "Reading https://pypi.org/simple/websocket-client/\n",
      "Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl#sha256=1151d5fb3a62dc129164292e1227655e4bbc5dd5340a5165dfae61128ec50aa9\n",
      "Best match: websocket-client 0.56.0\n",
      "Processing websocket_client-0.56.0-py2.py3-none-any.whl\n",
      "Installing websocket_client-0.56.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding websocket-client 0.56.0 to easy-install.pth file\n",
      "Installing wsdump.py script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/websocket_client-0.56.0-py3.7.egg\n",
      "Searching for Unidecode==1.1.1\n",
      "Reading https://pypi.org/simple/Unidecode/\n",
      "Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl#sha256=1d7a042116536098d05d599ef2b8616759f02985c85b4fef50c78a5aaf10822a\n",
      "Best match: Unidecode 1.1.1\n",
      "Processing Unidecode-1.1.1-py2.py3-none-any.whl\n",
      "Installing Unidecode-1.1.1-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding Unidecode 1.1.1 to easy-install.pth file\n",
      "Installing unidecode script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/Unidecode-1.1.1-py3.7.egg\n",
      "Searching for tqdm==4.36.1\n",
      "Reading https://pypi.org/simple/tqdm/\n",
      "Downloading https://files.pythonhosted.org/packages/e1/c1/bc1dba38b48f4ae3c4428aea669c5e27bd5a7642a74c8348451e0bd8ff86/tqdm-4.36.1-py2.py3-none-any.whl#sha256=dd3fcca8488bb1d416aa7469d2f277902f26260c45aa86b667b074cd44b3b115\n",
      "Best match: tqdm 4.36.1\n",
      "Processing tqdm-4.36.1-py2.py3-none-any.whl\n",
      "Installing tqdm-4.36.1-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding tqdm 4.36.1 to easy-install.pth file\n",
      "Installing tqdm script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/tqdm-4.36.1-py3.7.egg\n",
      "Searching for sphinx-autodoc-typehints==1.10.3\n",
      "Reading https://pypi.org/simple/sphinx-autodoc-typehints/\n",
      "Downloading https://files.pythonhosted.org/packages/00/83/87b8890a93b3994b49960716009c1effb6f7a1fef3a1ec553fda2a7c84de/sphinx_autodoc_typehints-1.10.3-py3-none-any.whl#sha256=27c9e6ef4f4451766ab8d08b2d8520933b97beb21c913f3df9ab2e59b56e6c6c\n",
      "Best match: sphinx-autodoc-typehints 1.10.3\n",
      "Processing sphinx_autodoc_typehints-1.10.3-py3-none-any.whl\n",
      "Installing sphinx_autodoc_typehints-1.10.3-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding sphinx-autodoc-typehints 1.10.3 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/sphinx_autodoc_typehints-1.10.3-py3.7.egg\n",
      "Searching for sphinx_rtd_theme==0.4.3\n",
      "Reading https://pypi.org/simple/sphinx_rtd_theme/\n",
      "Downloading https://files.pythonhosted.org/packages/60/b4/4df37087a1d36755e3a3bfd2a30263f358d2dea21938240fa02313d45f51/sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl#sha256=00cf895504a7895ee433807c62094cf1e95f065843bf3acd17037c3e9a2becd4\n",
      "Best match: sphinx-rtd-theme 0.4.3\n",
      "Processing sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl\n",
      "Installing sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding sphinx-rtd-theme 0.4.3 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/sphinx_rtd_theme-0.4.3-py3.7.egg\n",
      "Searching for Sphinx==2.2.0\n",
      "Reading https://pypi.org/simple/Sphinx/\n",
      "Downloading https://files.pythonhosted.org/packages/8e/4c/95a21788db2e1653e931420f561015a0bbc9bd4660c4520467ab9e733eb2/Sphinx-2.2.0-py3-none-any.whl#sha256=839a3ed6f6b092bb60f492024489cc9e6991360fb9f52ed6361acd510d261069\n",
      "Best match: Sphinx 2.2.0\n",
      "Processing Sphinx-2.2.0-py3-none-any.whl\n",
      "Installing Sphinx-2.2.0-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding Sphinx 2.2.0 to easy-install.pth file\n",
      "Installing sphinx-apidoc script to /usr/local/bin\n",
      "Installing sphinx-autogen script to /usr/local/bin\n",
      "Installing sphinx-build script to /usr/local/bin\n",
      "Installing sphinx-quickstart script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/Sphinx-2.2.0-py3.7.egg\n",
      "Searching for sh==1.12.14\n",
      "Reading https://pypi.org/simple/sh/\n",
      "Downloading https://files.pythonhosted.org/packages/4a/22/17b22ef5b049f12080f5815c41bf94de3c229217609e469001a8f80c1b3d/sh-1.12.14-py2.py3-none-any.whl#sha256=ae3258c5249493cebe73cb4e18253a41ed69262484bad36fdb3efcb8ad8870bb\n",
      "Best match: sh 1.12.14\n",
      "Processing sh-1.12.14-py2.py3-none-any.whl\n",
      "Installing sh-1.12.14-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding sh 1.12.14 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/sh-1.12.14-py3.7.egg\n",
      "Searching for requests-mock==1.7.0\n",
      "Reading https://pypi.org/simple/requests-mock/\n",
      "Downloading https://files.pythonhosted.org/packages/8c/f1/66c54a412543b29454102ae74b1454fce2d307b1c36e6bd2e9818394df88/requests_mock-1.7.0-py2.py3-none-any.whl#sha256=510df890afe08d36eca5bb16b4aa6308a6f85e3159ad3013bac8b9de7bd5a010\n",
      "Best match: requests-mock 1.7.0\n",
      "Processing requests_mock-1.7.0-py2.py3-none-any.whl\n",
      "Installing requests_mock-1.7.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding requests-mock 1.7.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/requests_mock-1.7.0-py3.7.egg\n",
      "Searching for requests==2.22.0\n",
      "Reading https://pypi.org/simple/requests/\n",
      "Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl#sha256=9cf5292fcd0f598c671cfc1e0d7d1a7f13bb8085e9a590f48c010551dc6c4b31\n",
      "Best match: requests 2.22.0\n",
      "Processing requests-2.22.0-py2.py3-none-any.whl\n",
      "Installing requests-2.22.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding requests 2.22.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/requests-2.22.0-py3.7.egg\n",
      "Searching for recommonmark==0.6.0\n",
      "Reading https://pypi.org/simple/recommonmark/\n",
      "Downloading https://files.pythonhosted.org/packages/94/de/334aaf73df8c0e77fb07f883d1e274344526196c137ef3479cb5e5aef086/recommonmark-0.6.0-py2.py3-none-any.whl#sha256=2ec4207a574289355d5b6ae4ae4abb29043346ca12cdd5f07d374dc5987d2852\n",
      "Best match: recommonmark 0.6.0\n",
      "Processing recommonmark-0.6.0-py2.py3-none-any.whl\n",
      "Installing recommonmark-0.6.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding recommonmark 0.6.0 to easy-install.pth file\n",
      "Installing cm2html script to /usr/local/bin\n",
      "Installing cm2latex script to /usr/local/bin\n",
      "Installing cm2man script to /usr/local/bin\n",
      "Installing cm2pseudoxml script to /usr/local/bin\n",
      "Installing cm2xetex script to /usr/local/bin\n",
      "Installing cm2xml script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/recommonmark-0.6.0-py3.7.egg\n",
      "Searching for regex==2019.8.19\n",
      "Reading https://pypi.org/simple/regex/\n",
      "Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz#sha256=587b62d48ca359d2d4f02d486f1f0aa9a20fbaf23a9d4198c4bed72ab2f6c849\n",
      "Best match: regex 2019.8.19\n",
      "Processing regex-2019.08.19.tar.gz\n",
      "Writing /tmp/easy_install-dd031k3n/regex-2019.08.19/setup.cfg\n",
      "Running regex-2019.08.19/setup.py -q bdist_egg --dist-dir /tmp/easy_install-dd031k3n/regex-2019.08.19/egg-dist-tmp-d127whk0\n",
      "BASE_DIR is /tmp/easy_install-dd031k3n/regex-2019.08.19\n",
      "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:490: UserWarning: Normalizing '2019.08.19' to '2019.8.19'\n",
      "  warnings.warn(tmpl.format(**locals()))\n",
      "\u001b[01m\u001b[Kregex_3/_regex.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfolded_char_at\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kregex_3/_regex.c:10625:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kfolded_len\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
      "     int \u001b[01;35m\u001b[Kfolded_len\u001b[m\u001b[K;\n",
      "         \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kregex_3/_regex.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfuzzy_match_group_fld\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kregex_3/_regex.c:11503:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdata.new_text_pos\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "     if (!\u001b[01;35m\u001b[Krecord_fuzzy(state, data.fuzzy_type, data.new_text_pos - data.step)\u001b[m\u001b[K)\n",
      "          \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kregex_3/_regex.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfuzzy_match_string_fld\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kregex_3/_regex.c:11270:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdata.new_text_pos\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "     if (!\u001b[01;35m\u001b[Krecord_fuzzy(state, data.fuzzy_type, data.new_text_pos - data.step)\u001b[m\u001b[K)\n",
      "          \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kregex_3/_regex.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kbasic_match\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kregex_3/_regex.c:11608:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdata.new_text_pos\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "     if (!\u001b[01;35m\u001b[Krecord_fuzzy(state, data.fuzzy_type, data.new_text_pos - data.step)\u001b[m\u001b[K)\n",
      "          \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kregex_3/_regex.c:11522:18:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdata.new_text_pos\u001b[m\u001b[K’ was declared here\n",
      "     RE_FuzzyData \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K;\n",
      "                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kregex_3/_regex.c:11369:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdata.new_text_pos\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "     if (!\u001b[01;35m\u001b[Krecord_fuzzy(state, data.fuzzy_type, data.new_text_pos - data.step)\u001b[m\u001b[K)\n",
      "          \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kregex_3/_regex.c:11288:18:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[Kdata.new_text_pos\u001b[m\u001b[K’ was declared here\n",
      "     RE_FuzzyData \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K;\n",
      "                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "regex.__pycache__._regex.cpython-37: module references __file__\n",
      "creating /usr/local/lib/python3.7/dist-packages/regex-2019.8.19-py3.7-linux-x86_64.egg\n",
      "Extracting regex-2019.8.19-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
      "Adding regex 2019.8.19 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/regex-2019.8.19-py3.7-linux-x86_64.egg\n",
      "Searching for pyzmq==18.1.0\n",
      "Reading https://pypi.org/simple/pyzmq/\n",
      "Downloading https://files.pythonhosted.org/packages/c7/6a/307e4a576787c7df1df6ebf56754c3fc8defcafa1a09ee22e9b961a390be/pyzmq-18.1.0-cp37-cp37m-manylinux1_x86_64.whl#sha256=343b9710a61f2b167673bea1974e70b5dccfe64b5ed10626798f08c1f7227e72\n",
      "Best match: pyzmq 18.1.0\n",
      "Processing pyzmq-18.1.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Installing pyzmq-18.1.0-cp37-cp37m-manylinux1_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding pyzmq 18.1.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/pyzmq-18.1.0-py3.7-linux-x86_64.egg\n",
      "Searching for py-rouge==1.1\n",
      "Reading https://pypi.org/simple/py-rouge/\n",
      "Downloading https://files.pythonhosted.org/packages/9c/1d/0bdbaf559fb7afe32308ebc84a2028600988212d7eb7fb9f69c4e829e4a0/py_rouge-1.1-py3-none-any.whl#sha256=9ae2a859a9edc6d25f3908e48706f7d82d6e78ea18954560c4cb21897dc1d270\n",
      "Best match: py-rouge 1.1\n",
      "Processing py_rouge-1.1-py3-none-any.whl\n",
      "Installing py_rouge-1.1-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding py-rouge 1.1 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/py_rouge-1.1-py3.7.egg\n",
      "Searching for py-gfm==0.1.4\n",
      "Reading https://pypi.org/simple/py-gfm/\n",
      "Downloading https://files.pythonhosted.org/packages/21/e0/be291e07b5e72e83285e4c0caf8060db0ab8d26f60bda254651e41493652/py_gfm-0.1.4-py2.py3-none-any.whl#sha256=d873541bcae194cc3b5053858719668834d3f1829342f0566ab3a48d0d744d58\n",
      "Best match: py-gfm 0.1.4\n",
      "Processing py_gfm-0.1.4-py2.py3-none-any.whl\n",
      "Installing py_gfm-0.1.4-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding py-gfm 0.1.4 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/py_gfm-0.1.4-py3.7.egg\n",
      "Searching for pexpect==4.7.0\n",
      "Reading https://pypi.org/simple/pexpect/\n",
      "Downloading https://files.pythonhosted.org/packages/0e/3e/377007e3f36ec42f1b84ec322ee12141a9e10d808312e5738f52f80a232c/pexpect-4.7.0-py2.py3-none-any.whl#sha256=2094eefdfcf37a1fdbfb9aa090862c1a4878e5c7e0e7e7088bdb511c558e5cd1\n",
      "Best match: pexpect 4.7.0\n",
      "Processing pexpect-4.7.0-py2.py3-none-any.whl\n",
      "Installing pexpect-4.7.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding pexpect 4.7.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/pexpect-4.7.0-py3.7.egg\n",
      "Searching for nltk==3.4.5\n",
      "Reading https://pypi.org/simple/nltk/\n",
      "Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip#sha256=bed45551259aa2101381bbdd5df37d44ca2669c5c3dad72439fa459b29137d94\n",
      "Best match: nltk 3.4.5\n",
      "Processing nltk-3.4.5.zip\n",
      "Writing /tmp/easy_install-k7jya9kp/nltk-3.4.5/setup.cfg\n",
      "Running nltk-3.4.5/setup.py -q bdist_egg --dist-dir /tmp/easy_install-k7jya9kp/nltk-3.4.5/egg-dist-tmp-0dtiuny1\n",
      "warning: no files found matching 'README.txt'\n",
      "warning: no files found matching 'Makefile' under directory '*.txt'\n",
      "warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "creating /usr/local/lib/python3.7/dist-packages/nltk-3.4.5-py3.7.egg\n",
      "Extracting nltk-3.4.5-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
      "Adding nltk 3.4.5 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/nltk-3.4.5-py3.7.egg\n",
      "Searching for h5py==2.10.0\n",
      "Reading https://pypi.org/simple/h5py/\n",
      "Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl#sha256=f0e25bb91e7a02efccb50aba6591d3fe2c725479e34769802fcdd4076abfa917\n",
      "Best match: h5py 2.10.0\n",
      "Processing h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Installing h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding h5py 2.10.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/h5py-2.10.0-py3.7-linux-x86_64.egg\n",
      "Searching for GitPython==3.0.3\n",
      "Reading https://pypi.org/simple/GitPython/\n",
      "Downloading https://files.pythonhosted.org/packages/ff/f8/05f58bd7852dad7edcf70a8de953b4fa39f61cdc13812ae62118be6ffa23/GitPython-3.0.3-py3-none-any.whl#sha256=6e97b9f0954807f30c2dd8e3165731ed6c477a1b365f194b69d81d7940a08332\n",
      "Best match: GitPython 3.0.3\n",
      "Processing GitPython-3.0.3-py3-none-any.whl\n",
      "Installing GitPython-3.0.3-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding GitPython 3.0.3 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/GitPython-3.0.3-py3.7.egg\n",
      "Searching for flake8-bugbear==19.8.0\n",
      "Reading https://pypi.org/simple/flake8-bugbear/\n",
      "Downloading https://files.pythonhosted.org/packages/9f/f8/170861859fb8ae97923b4fc28501dd25209925e25face836562d3e3f5ea2/flake8_bugbear-19.8.0-py35.py36.py37-none-any.whl#sha256=ded4d282778969b5ab5530ceba7aa1a9f1b86fa7618fc96a19a1d512331640f8\n",
      "Best match: flake8-bugbear 19.8.0\n",
      "Processing flake8_bugbear-19.8.0-py35.py36.py37-none-any.whl\n",
      "Installing flake8_bugbear-19.8.0-py35.py36.py37-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding flake8-bugbear 19.8.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/flake8_bugbear-19.8.0-py3.7.egg\n",
      "Searching for flake8==3.7.8\n",
      "Reading https://pypi.org/simple/flake8/\n",
      "Downloading https://files.pythonhosted.org/packages/26/de/3f815a99d86eb10464ea7bd6059c0172c7ca97d4bdcfca41051b388a653b/flake8-3.7.8-py2.py3-none-any.whl#sha256=8e9dfa3cecb2400b3738a42c54c3043e821682b9c840b0448c0503f781130696\n",
      "Best match: flake8 3.7.8\n",
      "Processing flake8-3.7.8-py2.py3-none-any.whl\n",
      "Installing flake8-3.7.8-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding flake8 3.7.8 to easy-install.pth file\n",
      "Installing flake8 script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/flake8-3.7.8-py3.7.egg\n",
      "Searching for docformatter==1.3.0\n",
      "Reading https://pypi.org/simple/docformatter/\n",
      "Downloading https://files.pythonhosted.org/packages/35/52/41c0152a44873c8f11f0f9fe21b680588ae0e2b20e4a0a9b4812f8decbdc/docformatter-1.3.tar.gz#sha256=c68c8db0952d7ec6423581915fde3f23d4be5eccc11eb28a3415b5cd0a1e4f73\n",
      "Best match: docformatter 1.3\n",
      "Processing docformatter-1.3.tar.gz\n",
      "Writing /tmp/easy_install-nxl6g5s9/docformatter-1.3/setup.cfg\n",
      "Running docformatter-1.3/setup.py -q bdist_egg --dist-dir /tmp/easy_install-nxl6g5s9/docformatter-1.3/egg-dist-tmp-nlgl_06l\n",
      "warning: no previously-included files found matching '.pre-commit-hooks.yaml'\n",
      "warning: no previously-included files found matching '.travis.yml'\n",
      "warning: no previously-included files found matching 'Makefile'\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "Moving docformatter-1.3-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
      "Adding docformatter 1.3 to easy-install.pth file\n",
      "Installing docformatter script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/docformatter-1.3-py3.7.egg\n",
      "Searching for emoji==0.5.4\n",
      "Reading https://pypi.org/simple/emoji/\n",
      "Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz#sha256=60652d3a2dcee5b8af8acb097c31776fb6d808027aeb7221830f72cdafefc174\n",
      "Best match: emoji 0.5.4\n",
      "Processing emoji-0.5.4.tar.gz\n",
      "Writing /tmp/easy_install-5lr0dq4y/emoji-0.5.4/setup.cfg\n",
      "Running emoji-0.5.4/setup.py -q bdist_egg --dist-dir /tmp/easy_install-5lr0dq4y/emoji-0.5.4/egg-dist-tmp-5kursy6s\n",
      "Moving emoji-0.5.4-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
      "Adding emoji 0.5.4 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/emoji-0.5.4-py3.7.egg\n",
      "Searching for docutils==0.14\n",
      "Reading https://pypi.org/simple/docutils/\n",
      "Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl#sha256=02aec4bd92ab067f6ff27a38a38a41173bf01bed8f89157768c1573f53e474a6\n",
      "Best match: docutils 0.14\n",
      "Processing docutils-0.14-py3-none-any.whl\n",
      "Installing docutils-0.14-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding docutils 0.14 to easy-install.pth file\n",
      "Installing rst2xml.py script to /usr/local/bin\n",
      "Installing rst2odt.py script to /usr/local/bin\n",
      "Installing rst2man.py script to /usr/local/bin\n",
      "Installing rst2pseudoxml.py script to /usr/local/bin\n",
      "Installing rst2xetex.py script to /usr/local/bin\n",
      "Installing rst2html5.py script to /usr/local/bin\n",
      "Installing rst2odt_prepstyles.py script to /usr/local/bin\n",
      "Installing rst2s5.py script to /usr/local/bin\n",
      "Installing rst2html.py script to /usr/local/bin\n",
      "Installing rst2html4.py script to /usr/local/bin\n",
      "Installing rst2latex.py script to /usr/local/bin\n",
      "Installing rstpep2html.py script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/docutils-0.14-py3.7.egg\n",
      "Searching for botocore==1.12.246\n",
      "Reading https://pypi.org/simple/botocore/\n",
      "Downloading https://files.pythonhosted.org/packages/6d/22/398af6ea8d5c6bac57154442068613df74e7adbf255417c6894ef49fda42/botocore-1.12.246-py2.py3-none-any.whl#sha256=6dcc121be4917cc731577a2ddff67b89cee6a4b0ec30241ce207a80a0d41990a\n",
      "Best match: botocore 1.12.246\n",
      "Processing botocore-1.12.246-py2.py3-none-any.whl\n",
      "Installing botocore-1.12.246-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding botocore 1.12.246 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/botocore-1.12.246-py3.7.egg\n",
      "Searching for boto3==1.9.246\n",
      "Reading https://pypi.org/simple/boto3/\n",
      "Downloading https://files.pythonhosted.org/packages/5b/cd/a888759c39670cac6b74027d3e3a93073ecb99135b1292d15bc2f3b6f90a/boto3-1.9.246-py2.py3-none-any.whl#sha256=9a84be232ff6432312c16b8e52cc5a01e6ff461cb9b50b3cafee24c6876a5012\n",
      "Best match: boto3 1.9.246\n",
      "Processing boto3-1.9.246-py2.py3-none-any.whl\n",
      "Installing boto3-1.9.246-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding boto3 1.9.246 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/boto3-1.9.246-py3.7.egg\n",
      "Searching for sphinxcontrib-qthelp\n",
      "Reading https://pypi.org/simple/sphinxcontrib-qthelp/\n",
      "Downloading https://files.pythonhosted.org/packages/2b/14/05f9206cf4e9cfca1afb5fd224c7cd434dcc3a433d6d9e4e0264d29c6cdb/sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl#sha256=bd9fc24bcb748a8d51fd4ecaade681350aa63009a347a8c14e637895444dfab6\n",
      "Best match: sphinxcontrib-qthelp 1.0.3\n",
      "Processing sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl\n",
      "Installing sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding sphinxcontrib-qthelp 1.0.3 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/sphinxcontrib_qthelp-1.0.3-py3.7.egg\n",
      "Searching for sphinxcontrib-jsmath\n",
      "Reading https://pypi.org/simple/sphinxcontrib-jsmath/\n",
      "Downloading https://files.pythonhosted.org/packages/c2/42/4c8646762ee83602e3fb3fbe774c2fac12f317deb0b5dbeeedd2d3ba4b77/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl#sha256=2ec2eaebfb78f3f2078e73666b1415417a116cc848b72e5172e596c871103178\n",
      "Best match: sphinxcontrib-jsmath 1.0.1\n",
      "Processing sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\n",
      "Installing sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding sphinxcontrib-jsmath 1.0.1 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/sphinxcontrib_jsmath-1.0.1-py3.7.egg\n",
      "Searching for sphinxcontrib-htmlhelp\n",
      "Reading https://pypi.org/simple/sphinxcontrib-htmlhelp/\n",
      "Downloading https://files.pythonhosted.org/packages/63/40/c854ef09500e25f6432dcbad0f37df87fd7046d376272292d8654cc71c95/sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl#sha256=d412243dfb797ae3ec2b59eca0e52dac12e75a241bf0e4eb861e450d06c6ed07\n",
      "Best match: sphinxcontrib-htmlhelp 2.0.0\n",
      "Processing sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl\n",
      "Installing sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding sphinxcontrib-htmlhelp 2.0.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/sphinxcontrib_htmlhelp-2.0.0-py3.7.egg\n",
      "Searching for sphinxcontrib-devhelp\n",
      "Reading https://pypi.org/simple/sphinxcontrib-devhelp/\n",
      "Downloading https://files.pythonhosted.org/packages/c5/09/5de5ed43a521387f18bdf5f5af31d099605c992fd25372b2b9b825ce48ee/sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl#sha256=8165223f9a335cc1af7ffe1ed31d2871f325254c0423bc0c4c7cd1c1e4734a2e\n",
      "Best match: sphinxcontrib-devhelp 1.0.2\n",
      "Processing sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl\n",
      "Installing sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding sphinxcontrib-devhelp 1.0.2 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/sphinxcontrib_devhelp-1.0.2-py3.7.egg\n",
      "Searching for sphinxcontrib-applehelp\n",
      "Reading https://pypi.org/simple/sphinxcontrib-applehelp/\n",
      "Downloading https://files.pythonhosted.org/packages/dc/47/86022665a9433d89a66f5911b558ddff69861766807ba685de2e324bd6ed/sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl#sha256=806111e5e962be97c29ec4c1e7fe277bfd19e9652fb1a4392105b43e01af885a\n",
      "Best match: sphinxcontrib-applehelp 1.0.2\n",
      "Processing sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl\n",
      "Installing sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding sphinxcontrib-applehelp 1.0.2 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/sphinxcontrib_applehelp-1.0.2-py3.7.egg\n",
      "Searching for idna<2.9,>=2.5\n",
      "Reading https://pypi.org/simple/idna/\n",
      "Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl#sha256=ea8b7f6188e6fa117537c3df7da9fc686d485087abf6ac197f9c46432f7e4a3c\n",
      "Best match: idna 2.8\n",
      "Processing idna-2.8-py2.py3-none-any.whl\n",
      "Installing idna-2.8-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding idna 2.8 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/idna-2.8-py3.7.egg\n",
      "Searching for commonmark>=0.8.1\n",
      "Reading https://pypi.org/simple/commonmark/\n",
      "Downloading https://files.pythonhosted.org/packages/b1/92/dfd892312d822f36c55366118b95d914e5f16de11044a27cf10a7d71bbbf/commonmark-0.9.1-py2.py3-none-any.whl#sha256=da2f38c92590f83de410ba1a3cbceafbc74fee9def35f9251ba9a971d6d66fd9\n",
      "Best match: commonmark 0.9.1\n",
      "Processing commonmark-0.9.1-py2.py3-none-any.whl\n",
      "Installing commonmark-0.9.1-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding commonmark 0.9.1 to easy-install.pth file\n",
      "Installing cmark script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/commonmark-0.9.1-py3.7.egg\n",
      "Searching for markdown<3.0\n",
      "Reading https://pypi.org/simple/markdown/\n",
      "Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl#sha256=9ba587db9daee7ec761cfc656272be6aabe2ed300fece21208e4aab2e457bc8f\n",
      "Best match: Markdown 2.6.11\n",
      "Processing Markdown-2.6.11-py2.py3-none-any.whl\n",
      "Installing Markdown-2.6.11-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding Markdown 2.6.11 to easy-install.pth file\n",
      "Installing markdown_py script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/Markdown-2.6.11-py3.7.egg\n",
      "Searching for gitdb2>=2.0.0\n",
      "Reading https://pypi.org/simple/gitdb2/\n",
      "Downloading https://files.pythonhosted.org/packages/52/7e/59f96b47f671b3fe0aa0c1b609531a540434b719a10c417581e25b383909/gitdb2-4.0.2-py3-none-any.whl#sha256=a1c974e5fab8c2c90192c1367c81cbc54baec04244bda1816e9c8ab377d1cba3\n",
      "Best match: gitdb2 4.0.2\n",
      "Processing gitdb2-4.0.2-py3-none-any.whl\n",
      "Installing gitdb2-4.0.2-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding gitdb2 4.0.2 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/gitdb2-4.0.2-py3.7.egg\n",
      "Searching for pyflakes<2.2.0,>=2.1.0\n",
      "Reading https://pypi.org/simple/pyflakes/\n",
      "Downloading https://files.pythonhosted.org/packages/84/f2/ed0ffb887f8138a8fe5a621b8c0bb9598bfb3989e029f6c6a85ee66628ee/pyflakes-2.1.1-py2.py3-none-any.whl#sha256=17dbeb2e3f4d772725c777fabc446d5634d1038f234e77343108ce445ea69ce0\n",
      "Best match: pyflakes 2.1.1\n",
      "Processing pyflakes-2.1.1-py2.py3-none-any.whl\n",
      "Installing pyflakes-2.1.1-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding pyflakes 2.1.1 to easy-install.pth file\n",
      "Installing pyflakes script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/pyflakes-2.1.1-py3.7.egg\n",
      "Searching for pycodestyle<2.6.0,>=2.5.0\n",
      "Reading https://pypi.org/simple/pycodestyle/\n",
      "Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl#sha256=95a2219d12372f05704562a14ec30bc76b05a5b297b21a5dfe3f6fac3491ae56\n",
      "Best match: pycodestyle 2.5.0\n",
      "Processing pycodestyle-2.5.0-py2.py3-none-any.whl\n",
      "Installing pycodestyle-2.5.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding pycodestyle 2.5.0 to easy-install.pth file\n",
      "Installing pycodestyle script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/pycodestyle-2.5.0-py3.7.egg\n",
      "Searching for mccabe<0.7.0,>=0.6.0\n",
      "Reading https://pypi.org/simple/mccabe/\n",
      "Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl#sha256=ab8a6258860da4b6677da4bd2fe5dc2c659cff31b3ee4f7f5d64e79735b80d42\n",
      "Best match: mccabe 0.6.1\n",
      "Processing mccabe-0.6.1-py2.py3-none-any.whl\n",
      "Installing mccabe-0.6.1-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding mccabe 0.6.1 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/mccabe-0.6.1-py3.7.egg\n",
      "Searching for untokenize\n",
      "Reading https://pypi.org/simple/untokenize/\n",
      "Downloading https://files.pythonhosted.org/packages/f7/46/e7cea8159199096e1df52da20a57a6665da80c37fb8aeb848a3e47442c32/untokenize-0.1.1.tar.gz#sha256=3865dbbbb8efb4bb5eaa72f1be7f3e0be00ea8b7f125c69cbd1f5fda926f37a2\n",
      "Best match: untokenize 0.1.1\n",
      "Processing untokenize-0.1.1.tar.gz\n",
      "Writing /tmp/easy_install-luft9fz7/untokenize-0.1.1/setup.cfg\n",
      "Running untokenize-0.1.1/setup.py -q bdist_egg --dist-dir /tmp/easy_install-luft9fz7/untokenize-0.1.1/egg-dist-tmp-8we5ko_u\n",
      "warning: no previously-included files found matching '.travis.yml'\n",
      "warning: no previously-included files found matching 'Makefile'\n",
      "warning: no previously-included files found matching 'test_acid.py'\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "Moving untokenize-0.1.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
      "Adding untokenize 0.1.1 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/untokenize-0.1.1-py3.7.egg\n",
      "Searching for jmespath<1.0.0,>=0.7.1\n",
      "Reading https://pypi.org/simple/jmespath/\n",
      "Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl#sha256=cdf6525904cc597730141d61b36f2e4b8ecc257c420fa2f4549bac2c2d0cb72f\n",
      "Best match: jmespath 0.10.0\n",
      "Processing jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Installing jmespath-0.10.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding jmespath 0.10.0 to easy-install.pth file\n",
      "Installing jp.py script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/jmespath-0.10.0-py3.7.egg\n",
      "Searching for s3transfer<0.3.0,>=0.2.0\n",
      "Reading https://pypi.org/simple/s3transfer/\n",
      "Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl#sha256=b780f2411b824cb541dbcd2c713d0cb61c7d1bcadae204cdddda2b35cef493ba\n",
      "Best match: s3transfer 0.2.1\n",
      "Processing s3transfer-0.2.1-py2.py3-none-any.whl\n",
      "Installing s3transfer-0.2.1-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding s3transfer 0.2.1 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/s3transfer-0.2.1-py3.7.egg\n",
      "Searching for gitdb>=4.0.1\n",
      "Reading https://pypi.org/simple/gitdb/\n",
      "Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl#sha256=6c4cc71933456991da20917998acbe6cf4fb41eeaab7d6d67fbc05ecd4c865b0\n",
      "Best match: gitdb 4.0.7\n",
      "Processing gitdb-4.0.7-py3-none-any.whl\n",
      "Installing gitdb-4.0.7-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding gitdb 4.0.7 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/gitdb-4.0.7-py3.7.egg\n",
      "Searching for smmap<5,>=3.0.1\n",
      "Reading https://pypi.org/simple/smmap/\n",
      "Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl#sha256=a9a7479e4c572e2e775c404dcd3080c8dc49f39918c2cf74913d30c4c478e3c2\n",
      "Best match: smmap 4.0.0\n",
      "Processing smmap-4.0.0-py2.py3-none-any.whl\n",
      "Installing smmap-4.0.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
      "Adding smmap 4.0.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.7/dist-packages/smmap-4.0.0-py3.7.egg\n",
      "Searching for scipy==1.4.1\n",
      "Best match: scipy 1.4.1\n",
      "Adding scipy 1.4.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for scikit-learn==0.22.2.post1\n",
      "Best match: scikit-learn 0.22.2.post1\n",
      "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for Pillow==7.1.2\n",
      "Best match: Pillow 7.1.2\n",
      "Adding Pillow 7.1.2 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for numpy==1.19.5\n",
      "Best match: numpy 1.19.5\n",
      "Adding numpy 1.19.5 to easy-install.pth file\n",
      "Installing f2py script to /usr/local/bin\n",
      "Installing f2py3 script to /usr/local/bin\n",
      "Installing f2py3.7 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for joblib==1.0.1\n",
      "Best match: joblib 1.0.1\n",
      "Adding joblib 1.0.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for six==1.15.0\n",
      "Best match: six 1.15.0\n",
      "Adding six 1.15.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for sphinxcontrib-serializinghtml==1.1.4\n",
      "Best match: sphinxcontrib-serializinghtml 1.1.4\n",
      "Adding sphinxcontrib-serializinghtml 1.1.4 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for snowballstemmer==2.1.0\n",
      "Best match: snowballstemmer 2.1.0\n",
      "Adding snowballstemmer 2.1.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for setuptools==56.1.0\n",
      "Best match: setuptools 56.1.0\n",
      "Adding setuptools 56.1.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for packaging==20.9\n",
      "Best match: packaging 20.9\n",
      "Adding packaging 20.9 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for imagesize==1.2.0\n",
      "Best match: imagesize 1.2.0\n",
      "Adding imagesize 1.2.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for Babel==2.9.1\n",
      "Best match: Babel 2.9.1\n",
      "Adding Babel 2.9.1 to easy-install.pth file\n",
      "Installing pybabel script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for alabaster==0.7.12\n",
      "Best match: alabaster 0.7.12\n",
      "Adding alabaster 0.7.12 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for Pygments==2.6.1\n",
      "Best match: Pygments 2.6.1\n",
      "Adding Pygments 2.6.1 to easy-install.pth file\n",
      "Installing pygmentize script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for Jinja2==2.11.3\n",
      "Best match: Jinja2 2.11.3\n",
      "Adding Jinja2 2.11.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for urllib3==1.24.3\n",
      "Best match: urllib3 1.24.3\n",
      "Adding urllib3 1.24.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for chardet==3.0.4\n",
      "Best match: chardet 3.0.4\n",
      "Adding chardet 3.0.4 to easy-install.pth file\n",
      "Installing chardetect script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for certifi==2020.12.5\n",
      "Best match: certifi 2020.12.5\n",
      "Adding certifi 2020.12.5 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for ptyprocess==0.7.0\n",
      "Best match: ptyprocess 0.7.0\n",
      "Adding ptyprocess 0.7.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for attrs==21.2.0\n",
      "Best match: attrs 21.2.0\n",
      "Adding attrs 21.2.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for entrypoints==0.3\n",
      "Best match: entrypoints 0.3\n",
      "Adding entrypoints 0.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for python-dateutil==2.8.1\n",
      "Best match: python-dateutil 2.8.1\n",
      "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for pyparsing==2.4.7\n",
      "Best match: pyparsing 2.4.7\n",
      "Adding pyparsing 2.4.7 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for pytz==2018.9\n",
      "Best match: pytz 2018.9\n",
      "Adding pytz 2018.9 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Searching for MarkupSafe==2.0.1\n",
      "Best match: MarkupSafe 2.0.1\n",
      "Adding MarkupSafe 2.0.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.7/dist-packages\n",
      "Finished processing dependencies for parlai==0.1.0\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/ParlAI.git ./ParlAI\n",
    "!cd ./ParlAI && git checkout convai2archive\n",
    "!cd ./ParlAI; python setup.py develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OJJ-L5RCyYT"
   },
   "source": [
    "**Example: **\n",
    "\n",
    "your persona: i just started college.\n",
    "\n",
    "your persona: i have 3 science classes.\n",
    "\n",
    "your persona: i work part time in the campus library.\n",
    "\n",
    "your persona: i am living at home but hope to live in the dorms next year.\n",
    "\n",
    "**Partner Dialogue**: hi how are you doing\n",
    "\n",
    "**Your Response**: great ! just got off work and relaxing before i study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oe72XiqFXCS0",
    "outputId": "32c2260e-bc04-4670-ba4f-b40523699542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ optional arguments: ] \n",
      "[  display_ignore_fields: agent_reply ]\n",
      "[  max_display_len: 1000 ]\n",
      "[  num_examples: 10 ]\n",
      "[ Main ParlAI Arguments: ] \n",
      "[  batchsize: 1 ]\n",
      "[  datapath: /content/ParlAI/data ]\n",
      "[  datatype: train ]\n",
      "[  download_path: /content/ParlAI/downloads ]\n",
      "[  hide_labels: False ]\n",
      "[  image_mode: raw ]\n",
      "[  init_opt: None ]\n",
      "[  multitask_weights: [1] ]\n",
      "[  numthreads: 1 ]\n",
      "[  show_advanced_args: False ]\n",
      "[  task: personachat ]\n",
      "[ ParlAI Model Arguments: ] \n",
      "[  dict_class: None ]\n",
      "[  init_model: None ]\n",
      "[  model: None ]\n",
      "[  model_file: None ]\n",
      "[ PytorchData Arguments: ] \n",
      "[  batch_length_range: 5 ]\n",
      "[  batch_sort_cache_type: pop ]\n",
      "[  batch_sort_field: text ]\n",
      "[  numworkers: 4 ]\n",
      "[  pytorch_context_length: -1 ]\n",
      "[  pytorch_datapath: None ]\n",
      "[  pytorch_include_labels: True ]\n",
      "[  pytorch_preprocess: False ]\n",
      "[  pytorch_teacher_batch_sort: False ]\n",
      "[  pytorch_teacher_dataset: None ]\n",
      "[  pytorch_teacher_task: None ]\n",
      "[  shuffle: False ]\n",
      "[ ParlAI Image Preprocessing Arguments: ] \n",
      "[  image_cropsize: 224 ]\n",
      "[  image_size: 256 ]\n",
      "[creating task(s): personachat]\n",
      "[building data: /content/ParlAI/data/Persona-Chat]\n",
      "[ downloading: http://parl.ai/downloads/personachat/personachat.tgz to /content/ParlAI/data/Persona-Chat/personachat.tgz ]\n",
      "Downloading personachat.tgz: 100% 223M/223M [00:10<00:00, 22.1MB/s]\n",
      "[ Checksum Successful ]\n",
      "unpacking personachat.tgz\n",
      "[loading fbdialog data:/content/ParlAI/data/Persona-Chat/personachat/train_self_original.txt]\n",
      "[personachat]: your persona: i just started college.\n",
      "your persona: i have 3 science classes.\n",
      "your persona: i work part time in the campus library.\n",
      "your persona: i am living at home but hope to live in the dorms next year.\n",
      "hi how are you doing\n",
      "[label_candidates: yea . the piano . before i graduated college .|yes . very warm . i love it .|nice meeting you , spend as much time at home now that you can , i wish i could .|he was . he was my favorite artist .|i was . she was an addict though . love hate relationship . in the strongest way|...and 15 more]\n",
      "[labels: great ! just got off work and relaxing before i study]\n",
      "~~\n",
      "[personachat]: nice where do you work\n",
      "[label_candidates: that is amazing to hear . i like to run with my dogs .|i did not it was so yucky out|not too bad so far|i am a bowler and professional one and i have two kids and you ?|yes it could , i am always sad ugh , how are you ?|...and 15 more]\n",
      "[labels: the library on campus , it is part time but really peaceful and easy]\n",
      "~~\n",
      "[personachat]: that is cool i just live off my girlfriends salary\n",
      "[label_candidates: i wish i knew how to play .|hey , they call me blue eyes . do you have a nickname ?|are you going to cook for me ?|no i am currently taking my boards for pharmacy .|they can come too . the more the merrier .|...and 15 more]\n",
      "[labels: i live at home , next year i want to move on campus though]\n",
      "~~\n",
      "[personachat]: that is cool do you like to cook\n",
      "[label_candidates: i am doing well do you like music ?|i will check them out . i am really going to miss my sister when i move .|were they really ? i did not know that . i love to learn .|hi . i am alright . what do you like to do ? i am a writer .|me and my parents and brother moved here !|...and 15 more]\n",
      "[labels: i do , i make this one dish with pork marinated in catalina dressing , its good]\n",
      "~~\n",
      "[personachat]: that sounds so interesting i like to cook brunch on the weekends\n",
      "[label_candidates: wow that is interesting to hear|me too ! what do you do for a living ? i am in finance .|helping people . i guess that is why i am a nurse .|i enjoy going to park and bird watching . love country music|its not as fun as biking , but it pays the bills .|...and 15 more]\n",
      "[labels: i do not cook a lot . this semester i have 3 different science classes]\n",
      "~~\n",
      "[personachat]: wow is that your major ?\n",
      "[label_candidates: willie nelson , hank williams iii . . . . all the usual stuff . . . plus thrash metal from norway|very short . under 5 feet tall . trying to lose another 20 pounds ! it is hard !|new england is a beautiful place to grow up . i work in connecticut now . nice weather .|for what ? i know oliva pope personally . i have not been on a boat ever ? you ?|what do you do for a living ?|...and 15 more]\n",
      "[labels: chemistry , but have a minor in biology]\n",
      "~~\n",
      "[personachat]: wow what do you want to do after school\n",
      "[label_candidates: i have written several romance novels under a different name . . . .|do you have any pets ? my dog , socks , lives at my parents house .|what reality show do you like ? i am going to fail math because of dungeons and dragons .|shopping . it is like my passion .|i drop off baking goods in my state where i reside .|...and 15 more]\n",
      "[labels: ideally i want to work for an energy company working on new energy and fuel sources]\n",
      "~~\n",
      "[personachat]: cool i wish i knew more about science\n",
      "[label_candidates: i have three , and am named for my grandmother .|exactleee . . oops i am not great at spelling|black i guess . what about you ?|yes and sunset also is a good time|oh . i eat about anything .|...and 15 more]\n",
      "[labels: it is difficult but i do enjoy it , just takes a lot of studying]\n",
      "- - - - - - - - - - - - - - - - - - - - -\n",
      "~~\n",
      "[personachat]: your persona: i have borderline personality disorder.\n",
      "your persona: it is my universe , and everyone else is just a character in it.\n",
      "your persona: i work as a dental assistant in a ritzy part of town.\n",
      "your persona: at night , i party hard in the atlanta club scene , and i never miss a music festival.\n",
      "how are you doing today ?\n",
      "[label_candidates: i am less afraid to drive as i am terrified of clowns though .|hi how are you today|rap and r b , i hate country tho|maybe you should find a job , i am looking for one , but nba is fun too|you must be a grown up .|...and 15 more]\n",
      "[labels: great ! just got back from some dbt therapy . it really helps me]\n",
      "~~\n",
      "[personachat]: what is that ? i am not familiar .\n",
      "[label_candidates: i have to hurry and clean up this mess if we are going to go out .|yes they are confused but not about being a boy or girl|princess from mario . what is your favorite song ?|i love texas i am going to live in australia next year for my boyfriend|wow that sounds interesting , my addiction to black coffee is out of control .|...and 15 more]\n",
      "[labels: dialectical behavioral therapy . i use it to help with my borderline personality]\n",
      "~~\n",
      "[ loaded 8939 episodes with a total of 65719 examples ]\n"
     ]
    }
   ],
   "source": [
    "# let's download and take a look at some examples of data in PersonaChat\n",
    "!python ./ParlAI/examples/display_data.py --task personachat --datatype train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "V3Ob4tEt1vNP",
    "outputId": "09c566fb-eaf4-4282-f7fe-50dd16017c75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='color: blue;'>\n",
       "  <b>Questions:</b>\n",
       "  <ul style='color: blue;'>\n",
       "    <li>What do the personalities look like?</li>\n",
       "    <li>How does creating bots with these simple personalities address consistency for chatbots? </li>\n",
       "    <li>What are some drawbacks/limitations of these specific personalities for addressing the problem of consistency?</li>\n",
       "  </ul>\n",
       "</p>\n",
       "\n",
       "\n",
       "<p style='color: red;'>\n",
       "  <b>Answers:</b>\n",
       "  <ul style='color: red;'>\n",
       "    <li>Personalities are just a few sentences describing a few aspects about the persona.</li>\n",
       "    <li>Using personas helps a little bit with the consistency problem. However, all other aspects will still be prune to consistency</li>\n",
       "    <li>Since we are providing a few general sentences about the personality, the model can still have consistency issues ouside the persona region.</li>\n",
       "  </ul>\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<p style='color: blue;'>\n",
    "  <b>Questions:</b>\n",
    "  <ul style='color: blue;'>\n",
    "    <li>What do the personalities look like?</li>\n",
    "    <li>How does creating bots with these simple personalities address consistency for chatbots? </li>\n",
    "    <li>What are some drawbacks/limitations of these specific personalities for addressing the problem of consistency?</li>\n",
    "  </ul>\n",
    "</p>\n",
    "\n",
    "\n",
    "<p style='color: red;'>\n",
    "  <b>Answers:</b>\n",
    "  <ul style='color: red;'>\n",
    "    <li>Personalities are just a few sentences describing a few aspects about the persona.</li>\n",
    "    <li>Using personas helps a little bit with the consistency problem. However, all other aspects will still be prune to consistency</li>\n",
    "    <li>Since we are providing a few general sentences about the personality, the model can still have consistency issues ouside the persona region.</li>\n",
    "  </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kyhri6NvYKda"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "***Let's understand how much data we have. Let's compute the following using ParlAI:***\n",
    "\n",
    "\n",
    "1.   **How many turns of data do we have?** In dialogue datasets, \"amount of data\" is measured in dialogue turns. Each time there is a single line of dialogue, that is called a \"turn\"\n",
    "2.   **On average, how many words form a model input?**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30SF6hN6DAjD",
    "outputId": "11ef8ce4-6e1c-4628-c12d-1c5d46f51880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ note: changing datatype from train to train:ordered ]\n",
      "[creating task(s): personachat]\n",
      "[loading fbdialog data:/content/ParlAI/data/Persona-Chat/personachat/train_self_original.txt]\n",
      "[ loaded 8939 episodes with a total of 65719 examples ]\n",
      "18s elapsed: {'exs': 65719, '%done': '100.00%', 'time_left': '0s', 'stats': '\n",
      "input:\n",
      "   utterances: 65719\n",
      "   avg utterance length: 18.356974390967604\n",
      "   tokens: 1206402\n",
      "   unique tokens: 14209\n",
      "   unique utterances: 64580\n",
      "labels:\n",
      "   utterances: 65719\n",
      "   avg utterance length: 11.929411585690591\n",
      "   tokens: 783989\n",
      "   unique tokens: 14507\n",
      "   unique utterances: 64119\n",
      "both:\n",
      "   utterances: 131438\n",
      "   avg utterance length: 15.143192988329098\n",
      "   tokens: 1990391\n",
      "   unique tokens: 18741\n",
      "   unique utterances: 128197\n",
      "'}\n"
     ]
    }
   ],
   "source": [
    "!python ./ParlAI/parlai/scripts/data_stats.py -t personachat -dt train -ltim 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vwk7krxU57M"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "How are dialogue models evaluated?\n",
    "\n",
    "\n",
    "\n",
    "1.   **Automatic Evaluation**: Hits @ 1, Hits @ 5, Hits @ 10, F1\n",
    "2.   **Human Evaluation**: Pairwise Comparison, Human Rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "pGI2fFPLVRSJ",
    "outputId": "e7c25adf-abfe-4d23-b7b7-7c43fb6dfcf8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='color: blue;'>\n",
       "  <b>Questions:</b>\n",
       "  <ul style='color: blue;'>\n",
       "    <li>Take some notes about what these metrics are and what they mean here</li>\n",
       "  </ul>\n",
       "</p>\n",
       "\n",
       "<p style='color: red;'>\n",
       "  <b>Answers:</b>\n",
       "  <ul style='color: red;'>\n",
       "    <li>Hits@1: means how many times the most probable reply of the model is the gold reply... it's equal to accuracy.</li>\n",
       "    <li>Hits@5: means how many times the most probable five replies of the model contains the gold reply.</li>\n",
       "    <li>Hits@10: means how many times the most probable ten replies of the model contains the gol.d reply.</li>\n",
       "    <li>\n",
       "        <ul>\n",
       "            <li>Precision: how many words in the prediction found in the gold reply</li>\n",
       "            <li>Recall: how many words in the answer found in the prediction.</li>\n",
       "            <li>F1: 2PR/(P+R).</li>\n",
       "        </ul>\n",
       "    </li>\n",
       "    <li>Pairwise Comparison: a human has to guess which one is the bot and which one is the human answer.</li>\n",
       "    <li>Human Rating: a human has to score the model performance based on the predictions.</li>\n",
       "  </ul>\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<p style='color: blue;'>\n",
    "  <b>Questions:</b>\n",
    "  <ul style='color: blue;'>\n",
    "    <li>Take some notes about what these metrics are and what they mean here</li>\n",
    "  </ul>\n",
    "</p>\n",
    "\n",
    "<p style='color: red;'>\n",
    "  <b>Answers:</b>\n",
    "  <ul style='color: red;'>\n",
    "    <li>Hits@1: means how many times the most probable reply of the model is the gold reply... it's equal to accuracy.</li>\n",
    "    <li>Hits@5: means how many times the most probable five replies of the model contains the gold reply.</li>\n",
    "    <li>Hits@10: means how many times the most probable ten replies of the model contains the gol.d reply.</li>\n",
    "    <li>\n",
    "        <ul>\n",
    "            <li>Precision: how many words in the prediction found in the gold reply</li>\n",
    "            <li>Recall: how many words in the answer found in the prediction.</li>\n",
    "            <li>F1: 2PR/(P+R).</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Pairwise Comparison: a human has to guess which one is the bot and which one is the human answer.</li>\n",
    "    <li>Human Rating: a human has to score the model performance based on the predictions.</li>\n",
    "  </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGLnbj8Ee--h"
   },
   "source": [
    "<font color='red'>\n",
    "<ul>\n",
    "    \n",
    "\n",
    "</ul>\n",
    "</font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpkwidfAZ_7p"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuqnjqxbZ_W2"
   },
   "source": [
    "There are two main kinds of dialogue models. \n",
    "\n",
    "- *Retrieval* Models analyze the current dialogue context and try to find appropriate responses in the dataset.\n",
    "\n",
    "- *Generative* Models analyze the current dialogue context\n",
    "and try to write an answer, word by word, from left to right.\n",
    "This can be thought of as an application of sequence-to-sequence models,  where the \"encoder side\" is the dialogue history and the \"decoder side\" is the dialogue response your chatbot should generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "JPRp1MlH3n0h",
    "outputId": "7492983d-fbc5-4609-c21d-af107138b8f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='color: blue;'>\n",
       "  <b>Questions:</b>\n",
       "  <ul style='color: blue;'>\n",
       "    <li>Let's discuss the pros/cons of retrieval compared to generative models - Are there settings when you might want to use one over the other?</li>\n",
       "    <li>Compare a chit-chat application to something like booking a movie ticket- would you want to use generative, retrieval, or something else to accomplish that task? Why?</li>\n",
       "    <li>How can you evaluate generative models with the metrics we discussed before? How do you think they will perform compared to retrieval models?</li>\n",
       "    <li>In lecture, Antoine mentioned issues with generative model generation being generic and short. How does this happen in beam search?</li>\n",
       "</ul>\n",
       "</p>\n",
       "\n",
       "<p style='color: red;'>\n",
       "  <b>Answers:</b>\n",
       "  <ul style='color: red;'>\n",
       "      <li>\n",
       "        The pros of retrieval models over generative models:\n",
       "        <ul>\n",
       "            <li>Retrieval models works better than generative since text generation is much harder than retrieval.</li>\n",
       "            <li>Retrieval models have more diversity in the model's responses.</li>\n",
       "            <li>Retrieval models are better model for specific-domain.</li>\n",
       "\n",
       "        </ul>\n",
       "        The cons of retrieval models over generative models:\n",
       "        <ul>\n",
       "            <li>Generative models are easier to train than retrieval..</li>\n",
       "            <li>Generative models adapt easily to new terms such as COVID.</li>\n",
       "            <li>Generative models are better model for open-domain (chit-chat).</li>\n",
       "        </ul>\n",
       "      </li>\n",
       "      <li>Probably I would choose a retrieval model since this is a goal-oriented bot. Retrieval models are bettern than Generative models in this area.</li>\n",
       "      <li>Generative models can be evaluated using BLEU or perplexity. I think generative model will be worse than retrieval since retrieval gets actual replies.</li>\n",
       "      <li>Short answers are more frequent in the data, so they will be more appealing to the beam search.</li>\n",
       "    </ul>\n",
       "</p>\n",
       "<b> If you would like me to discuss how to actually use generative models in dialog, please say something! Otherwise, we will skip.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<p style='color: blue;'>\n",
    "  <b>Questions:</b>\n",
    "  <ul style='color: blue;'>\n",
    "    <li>Let's discuss the pros/cons of retrieval compared to generative models - Are there settings when you might want to use one over the other?</li>\n",
    "    <li>Compare a chit-chat application to something like booking a movie ticket- would you want to use generative, retrieval, or something else to accomplish that task? Why?</li>\n",
    "    <li>How can you evaluate generative models with the metrics we discussed before? How do you think they will perform compared to retrieval models?</li>\n",
    "    <li>In lecture, Antoine mentioned issues with generative model generation being generic and short. How does this happen in beam search?</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "<p style='color: red;'>\n",
    "  <b>Answers:</b>\n",
    "  <ul style='color: red;'>\n",
    "      <li>\n",
    "        The pros of retrieval models over generative models:\n",
    "        <ul>\n",
    "            <li>Retrieval models works better than generative since text generation is much harder than retrieval.</li>\n",
    "            <li>Retrieval models have more diversity in the model's responses.</li>\n",
    "            <li>Retrieval models are better model for specific-domain.</li>\n",
    "\n",
    "        </ul>\n",
    "        The cons of retrieval models over generative models:\n",
    "        <ul>\n",
    "            <li>Generative models are easier to train than retrieval..</li>\n",
    "            <li>Generative models adapt easily to new terms such as COVID.</li>\n",
    "            <li>Generative models are better model for open-domain (chit-chat).</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>Probably I would choose a retrieval model since this is a goal-oriented bot. Retrieval models are bettern than Generative models in this area.</li>\n",
    "      <li>Generative models can be evaluated using BLEU or perplexity. I think generative model will be worse than retrieval since retrieval gets actual replies.</li>\n",
    "      <li>Short answers are more frequent in the data, so they will be more appealing to the beam search.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "<b> If you would like me to discuss how to actually use generative models in dialog, please say something! Otherwise, we will skip.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_99CoAwaW2w"
   },
   "source": [
    "### Retrieval Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAfk4Km8bY_Y"
   },
   "source": [
    "Let's train a model to do retrieval first. We will try the *Memory Net.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyNOObOkbYTQ"
   },
   "outputs": [],
   "source": [
    "# We can train a model with the following command: \n",
    "# !python ./ParlAI/examples/train_model.py -m kv_memnn -t personachat -dt train -veps 0.25 --model-file persona_chat_retrieval_model -vmt accuracy\n",
    "\n",
    "# but we have limited time in the tutorial, so let's use an already pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gylhJvZwa0Vp"
   },
   "source": [
    "Quick Parameter Refresher:\n",
    "\n",
    "\n",
    "*  `-m ` means which model we're going to use. Recall retrieval models are trained to rank the true response higher over a set of potential responses from the dataset (in ParlAI, these are called the \"label candidates\"). When it's time to write a dialogue response, the retrieval model returns the response that is ranked the highest\n",
    "*  -`t` refers to the task. Here, we are training on PersonaChat data.\n",
    "* `-dt` refers to the data split. We want to train our model, so we are using the training set.\n",
    "* `-veps` refers to how often we should evaluate during training, our performance on validation. recall this is important because models, particularly neural ones, have the capacity to memorize the training dataset. So it's important to check how the model is doing on the validation set.\n",
    "* `--model-file` refers to when your model is saved, what should the filename be\n",
    "*  `-vmt` refers to the metric which we'll use to decide which model is the best. We'll cover this in the next section\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6wdfxEccAAp"
   },
   "source": [
    "**Let's interact with the model to get a sense of what it's learning. **How is this chat going to work?\n",
    "\n",
    "\n",
    "\n",
    "1.   You will be assigned a persona. You will chat to the model by typing in the chat box.\n",
    "2.   The chatbot also has a persona. It's secret and hidden from you!\n",
    "3.   When you've finished chatting with this bot, type [DONE] and a new model persona will be assigned to the bot, so you can talk to a new bot. \n",
    "4.   When you move on to the next chatbot persona, the previous persona will be revealed. \n",
    "\n",
    "Interact with the chatbots and the personas. **Try to think about the following:**\n",
    "\n",
    "*   Do the chatbots follow their persona a lot?\n",
    "*   Was it difficult to follow your persona?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdyaEgpcI7UL",
    "outputId": "321f1c6b-0d58-4f79-e694-d1e9bb0672d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ warning: overriding opt['model_file'] to /content/ParlAI/data/models/convai2/kvmemnn/model (previously: /checkpoint/jase/20180328/kvmemnn_sweep10/persona-self_rephraseTrn-True_rephraseTst-False_lr-0.1_esz-2000_margin-0.1_tfidf-False_shareEmb-True_hops1_lins0/model )]\n",
      "[ creating KvmemnnAgent ]\n",
      "Dictionary: loading dictionary from /content/ParlAI/data/models/convai2/kvmemnn/model.dict\n",
      "[ num words =  19153 ]\n",
      "Loading existing model params from /content/ParlAI/data/models/convai2/kvmemnn/model\n",
      "[loading candidates: /content/ParlAI/data/models/convai2/kvmemnn/model.candspair*]\n",
      "[caching..]\n",
      "=init done=\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "[creating task(s): parlai.agents.local_human.local_human:LocalHumanAgent]\n",
      "Enter [DONE] if you want to end the episode.\n",
      "\n",
      "[ optional arguments: ] \n",
      "[  display_examples: False ]\n",
      "[  display_ignore_fields: label_candidates,text_candidates ]\n",
      "[  display_prettify: False ]\n",
      "[ Main ParlAI Arguments: ] \n",
      "[  batchsize: 1 ]\n",
      "[  datapath: /content/ParlAI/data ]\n",
      "[  datatype: train ]\n",
      "[  download_path: /private/home/jase/src/ParlAI/downloads ]\n",
      "[  hide_labels: False ]\n",
      "[  image_mode: raw ]\n",
      "[  init_opt: None ]\n",
      "[  multitask_weights: [1] ]\n",
      "[  numthreads: 40 ]\n",
      "[  show_advanced_args: False ]\n",
      "[  task: convai2:SelfRevisedTeacher ]\n",
      "[ ParlAI Model Arguments: ] \n",
      "[  dict_class: parlai.core.dict:DictionaryAgent ]\n",
      "[  init_model: None ]\n",
      "[  model: projects.personachat.kvmemnn.kvmemnn:KvmemnnAgent ]\n",
      "[  model_file: /content/ParlAI/data/models/convai2/kvmemnn/model ]\n",
      "[ Local Human Arguments: ] \n",
      "[  local_human_candidates_file: None ]\n",
      "[  single_turn: False ]\n",
      "[ ParlAI Image Preprocessing Arguments: ] \n",
      "[  image_cropsize: 224 ]\n",
      "[  image_size: 256 ]\n",
      "[ Dictionary Arguments: ] \n",
      "[  bpe_debug: False ]\n",
      "[  dict_endtoken: __END__ ]\n",
      "[  dict_file: /content/ParlAI/data/models/convai2/kvmemnn/model.dict ]\n",
      "[  dict_initpath: None ]\n",
      "[  dict_language: english ]\n",
      "[  dict_lower: False ]\n",
      "[  dict_max_ngram_size: -1 ]\n",
      "[  dict_maxtokens: -1 ]\n",
      "[  dict_minfreq: 0 ]\n",
      "[  dict_nulltoken: __NULL__ ]\n",
      "[  dict_starttoken: __START__ ]\n",
      "[  dict_textfields: text,labels ]\n",
      "[  dict_tokenizer: split ]\n",
      "[  dict_unktoken: __UNK__ ]\n",
      "[ Kvmemnn Arguments: ] \n",
      "[  cache_size: 1000 ]\n",
      "[  embeddingnorm: 10 ]\n",
      "[  embeddingsize: 2000 ]\n",
      "[  history_length: 100 ]\n",
      "[  history_replies: label ]\n",
      "[  hops: 1 ]\n",
      "[  interactive_mode: False ]\n",
      "[  kvmemnn_debug: False ]\n",
      "[  learningrate: 0.1 ]\n",
      "[  lins: 0 ]\n",
      "[  loadcands: True ]\n",
      "[  loss: cosine ]\n",
      "[  margin: 0.1 ]\n",
      "[  neg_samples: 10 ]\n",
      "[  optimizer: sgd ]\n",
      "[  parrot_neg: 0 ]\n",
      "[  share_embeddings: True ]\n",
      "[  take_next_utt: False ]\n",
      "[  tfidf: False ]\n",
      "[  truncate: -1 ]\n",
      "[  twohop_blend: 0 ]\n",
      "[  twohop_range: 100 ]\n",
      "[creating task(s): convai2:both]\n",
      "[loading fbdialog data:/content/ParlAI/data/ConvAI2/train_both_original.txt]\n",
      "your persona: my favorite is rock fish.\n",
      "your persona: i m going riding on my boat today.\n",
      "your persona: i love tuna.\n",
      "your persona: i live in cape hatteras.\n",
      "your persona: i'm a fisherman.\n",
      "Enter [DONE] if you want a new partner at any time.\n",
      "Enter Your Message: Traceback (most recent call last):\n",
      "  File \"./ParlAI/projects/convai2/interactive.py\", line 126, in <module>\n",
      "    interactive(parser.parse_args(print_args=False), print_parser=parser)\n",
      "  File \"./ParlAI/projects/convai2/interactive.py\", line 102, in interactive\n",
      "    acts[0] = agents[0].act()\n",
      "  File \"/content/ParlAI/parlai/agents/local_human/local_human.py\", line 56, in act\n",
      "    reply_text = input(\"Enter Your Message: \")\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python ./ParlAI/projects/convai2/interactive.py -mf models:convai2/kvmemnn/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "hNbf3YEp31Z0",
    "outputId": "e74060fa-3563-45b9-d341-e20a46ee0437"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='color: blue;'>\n",
       "  <b>Questions:</b>\n",
       "  <ul style='color: blue;'>\n",
       "    <li>What does this model seem to be doing well? What is it doing poorly? </li>\n",
       "    <li>Why might it be performing poorly? What kind of experiment could you design to test your hypothesis?</li>\n",
       "    <li>How do we know if we need to use a more complex model? Would we always want to use a more complex model? Why or why not?</li>\n",
       "  </ul>\n",
       "</p>\n",
       "\n",
       "\n",
       "<p style='color: red;'>\n",
       "  <b>Answers:</b>\n",
       "  <ul style='color: red;'>\n",
       "    <li>Generating a grammatically correct sentences is a good thing. And a bad thing is consistency.</li>\n",
       "    <li>Because the persona doesn't control all aspects, so the model generates sentences related to the persona but not consistent with earlier predictions.\n",
       "        To test this hypothesis, we can give the model exact information (like name for example) and check if it remebers that exact information during dialogue or not.</li>\n",
       "    <li>When the model isn't able to capture the different aspects in the persona (underfitting). Not exactly, since complex models are harder to train and more prune to overfitting.</li>\n",
       "  </ul>\n",
       "</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<p style='color: blue;'>\n",
    "  <b>Questions:</b>\n",
    "  <ul style='color: blue;'>\n",
    "    <li>What does this model seem to be doing well? What is it doing poorly? </li>\n",
    "    <li>Why might it be performing poorly? What kind of experiment could you design to test your hypothesis?</li>\n",
    "    <li>How do we know if we need to use a more complex model? Would we always want to use a more complex model? Why or why not?</li>\n",
    "  </ul>\n",
    "</p>\n",
    "\n",
    "\n",
    "<p style='color: red;'>\n",
    "  <b>Answers:</b>\n",
    "  <ul style='color: red;'>\n",
    "    <li>Generating a grammatically correct sentences is a good thing. And a bad thing is consistency.</li>\n",
    "    <li>Because the persona doesn't control all aspects, so the model generates sentences related to the persona but not consistent with earlier predictions.\n",
    "        To test this hypothesis, we can give the model exact information (like name for example) and check if it remebers that exact information during dialogue or not.</li>\n",
    "    <li>When the model isn't able to capture the different aspects in the persona (underfitting). Not exactly, since complex models are harder to train and more prune to overfitting.</li>\n",
    "  </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_SYFM2UaUuq"
   },
   "outputs": [],
   "source": [
    "# Here is a command to train a Transformer Ranker model if you would like to try it out\n",
    "# !python ./ParlAI/examples/train_model.py -m transformer/ranker -t personachat -dt train -veps 0.25 --model-file persona_chat_retrieval_model -vmt accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "-1pAkQdt4n5_",
    "outputId": "1a3e014a-787e-40e2-e275-622d5fa458c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='color: blue;'>\n",
       "  <b>Questions:</b>\n",
       "  <ul style='color: blue;'>\n",
       "    <li>Are the models using the persona that we have provided? How can you tell? If I asked you to prove it to me, what experiments could you conduct? </li>\n",
       "    <li>Previously, we computed some statistics about how long the persona is in the training data. The model has also only seen words present in the training dataset. But what happens if you push the model outside of what data it's been trained on? What kind of performance do you get? Why does this happen, and what could you do if you wanted to improve the model's ability to generalize? </li>\n",
       "    <li>In ParlAI, we've set the parameters to save the model's best performance based on validation accuracy. What would happen if we saved the model based on the best training accuracy? Why does this happen? (if you like, try this out on your own and see the effect when you interact with the bot)</li>\n",
       "  </ul>\n",
       "</p>\n",
       "\n",
       "<p style='color: red;'>\n",
       "  <b>Answers:</b>\n",
       "  <ul style='color: red;'>\n",
       "    <li>Yes, the model is using the persona. Because of the generated sentences caught the gist of the persona. We can check the number of key words in the persona and how many they were mentioned in the generated sentences.</li>\n",
       "    <li> If we pushed the model out of the domain, consistency issues will increase. Also, the model performance will be worse and consisteny issues will rise. Because the model has no prior knowledge of the dialogue which opens all possibilities. We can improve the generalization by training a generative model over general data... a lot of data.</li>\n",
       "    <li>It will be prune to overfitting. Training accuracy measures the model's ability to memorize.</li>\n",
       "  </ul>\n",
       "</p>\n",
       "\n",
       "<b> If you would like me to discuss how to use BERT in dialog, please say something! Otherwise, we will skip.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<p style='color: blue;'>\n",
    "  <b>Questions:</b>\n",
    "  <ul style='color: blue;'>\n",
    "    <li>Are the models using the persona that we have provided? How can you tell? If I asked you to prove it to me, what experiments could you conduct? </li>\n",
    "    <li>Previously, we computed some statistics about how long the persona is in the training data. The model has also only seen words present in the training dataset. But what happens if you push the model outside of what data it's been trained on? What kind of performance do you get? Why does this happen, and what could you do if you wanted to improve the model's ability to generalize? </li>\n",
    "    <li>In ParlAI, we've set the parameters to save the model's best performance based on validation accuracy. What would happen if we saved the model based on the best training accuracy? Why does this happen? (if you like, try this out on your own and see the effect when you interact with the bot)</li>\n",
    "  </ul>\n",
    "</p>\n",
    "\n",
    "<p style='color: red;'>\n",
    "  <b>Answers:</b>\n",
    "  <ul style='color: red;'>\n",
    "    <li>Yes, the model is using the persona. Because of the generated sentences caught the gist of the persona. We can check the number of key words in the persona and how many they were mentioned in the generated sentences.</li>\n",
    "    <li> If we pushed the model out of the domain, consistency issues will increase. Also, the model performance will be worse and consisteny issues will rise. Because the model has no prior knowledge of the dialogue which opens all possibilities. We can improve the generalization by training a generative model over general data... a lot of data.</li>\n",
    "    <li>It will be prune to overfitting. Training accuracy measures the model's ability to memorize.</li>\n",
    "  </ul>\n",
    "</p>\n",
    "\n",
    "<b> If you would like me to discuss how to use BERT in dialog, please say something! Otherwise, we will skip.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTHItY-QdNtw"
   },
   "source": [
    "### [for self exploration] Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GM6LaBzbe6Za"
   },
   "source": [
    "Generative models must produce word for word what they are going to say next in the dialogue. When predicting the next word, it produces a probability distribution over the entire vocabulary space for which word to generate next. To reduce the vocabulary space, we will use **byte-pair encoding** (BPE). \n",
    "\n",
    "*How does BPE work?* The BPE algorithm takes as input the training data and the number of *operations* it can do. It passes over the training set and tries to create sub-word units. For example, the word \"beautiful\" might be split into \"beau\" \"ti\" \"ful\". Each time it splits a word into sub-words, that is one operation. The final vocabulary output consists of these subwords. So \"ful\" can be part of \"beautiful\" and part of \"fruitful\" and so on.\n",
    "\n",
    "\n",
    "**Questions to ask yourself**:\n",
    "\n",
    "\n",
    "1.   Why is it important to keep the vocabulary space small?\n",
    "2.   What does perplexity measure? Why would we use it as a training objective? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4gNbbAugACx"
   },
   "outputs": [],
   "source": [
    "# !python ./ParlAI/examples/train_model.py -m transformer/generator -t personachat -dt train -veps 0.25 --model-file persona_chat_generative_model -vmt ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHpD0Ccb1zhd"
   },
   "source": [
    "## Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHdsZ3Sq12n6"
   },
   "source": [
    "**What did we learn about dialogue modeling? Review Questions to ask yourself**\n",
    "\n",
    "*   How do retrieval models work? What about generative? What are their pros and cons?\n",
    "*   What are some important traits of dialogue systems? How might the traits differ for different dialogue tasks?\n",
    "\n",
    "\n",
    "**General Takeaways about Machine Learning and Experimentation:**\n",
    "\n",
    "*   We don't try models just to try them - try to have a reason for conducting an experiment. As we did in the lab, try to analyze what's working well in your models and working poorly. Try to use these reasons to guide why you might want to try other models. Complex is not necessarily better. \n",
    "*   Certain models can be better for certain tasks. As we've seen, generative models are working really well for tasks such as machine translation, but have a bit to go before becoming general purpose dialogue generators. \n",
    "\n",
    "\n",
    "\n",
    "**I'm really interested in dialogue! What can I do to learn more?**\n",
    "\n",
    "\n",
    "*   Play around in ParlAI: ParlAI is a general library with many great dialogue models and code for them. It also provides a standard interface to access datasets and interact with various models. \n",
    "*   Read the PersonaChat Paper: https://arxiv.org/pdf/1801.07243.pdf\n",
    "*   Dialog using knowledge: One challenge of these chit chat systems is they do not concretely know any facts. So if you want to chat about a specific topic, the models cannot produce any relevant information - they say generic utterances or incorrect facts. One way to remedy this is to incorporate **knowledge** into the dialogue agents. This has been investigated in many different ways, but one of the first papers to show this is https://arxiv.org/abs/1811.01241. In this work, data is collected by asking one speaker to reference Wikipedia sentences.\n",
    "* Dialog with BERT: pretty new,  there is an investigation of two ways to use BERT in this paper: https://arxiv.org/abs/1903.03094. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ammi_dnlp_lab2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
